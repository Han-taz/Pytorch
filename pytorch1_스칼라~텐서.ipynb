{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a95dd8e3-c3c4-4a9e-aa17-62b3c7040809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\a\\anaconda3\\lib\\site-packages (1.12.1)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\a\\anaconda3\\lib\\site-packages (from torch) (4.4.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d69241a-91a5-43cf-a9ff-5329c5c77d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff22fe0a-79a0-46bf-8479-24f14c16bc13",
   "metadata": {},
   "source": [
    "# 1차원 텐서(=벡터)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "562917d5-bf8b-40ce-b20e-8e674c1cbca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 2., 3., 4., 5., 6.])\n"
     ]
    }
   ],
   "source": [
    "t_1d = torch.FloatTensor([0., 1., 2., 3., 4., 5., 6.])\n",
    "print(t_1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9be5b7e1-ac72-4674-8d47-7dc52803d10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "torch.Size([7])\n",
      "torch.Size([7])\n"
     ]
    }
   ],
   "source": [
    "print(t_1d.dim())  # rank. 즉, 차원\n",
    "print(t_1d.shape)  # shape\n",
    "print(t_1d.size()) # shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7bfca0af-eb50-466a-b730-062fc4921a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.) tensor(1.) tensor(6.)\n",
      "tensor([2., 3., 4.]) tensor([4., 5.])\n",
      "tensor([0., 1.]) tensor([3., 4., 5., 6.])\n"
     ]
    }
   ],
   "source": [
    "print(t_1d[0], t_1d[1], t_1d[-1])  # 인덱스로 접근\n",
    "print(t_1d[2:5], t_1d[4:-1])    # 슬라이싱\n",
    "print(t_1d[:2], t_1d[3:])       # 슬라이싱"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580e0db8-c286-47c3-b568-98a6f8835da1",
   "metadata": {},
   "source": [
    "# 2차원 텐서(=행렬)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8108403f-3f44-4a1b-9a5d-53398399625c",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_2d = torch.FloatTensor([[1., 2., 3.],\n",
    "                       [4., 5., 6.],\n",
    "                       [7., 8., 9.],\n",
    "                       [10., 11., 12.]\n",
    "                      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d07318a-d5a5-46f7-890e-0a5d1505374b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "torch.Size([4, 3])\n"
     ]
    }
   ],
   "source": [
    "print(t_2d.dim())  # rank. 즉, 차원\n",
    "print(t_2d.size()) # shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a7201beb-579b-489a-99a7-9a2dde1926ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.)\n",
      "torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "print(t_2d[1, 0]) \n",
    "print(t_2d[1, 0].size()) # ↑ 위의 경우의 크기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "80b52fb7-a13b-4f4e-9529-f27257d424c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8.)\n",
      "torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "print(t_2d[2, 1]) \n",
    "print(t_2d[2, 1].size()) # ↑ 위의 경우의 크기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d70cba9-93b0-4a45-91c3-b857b73d0d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9.)\n",
      "torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "print(t_2d[2, 2]) \n",
    "print(t_2d[2, 2].size()) # ↑ 위의 경우의 크기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0006ed81-3af5-4dbd-b3d6-7a09604260b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.,  4.,  7., 10.])\n",
      "torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "print(t_2d[:, 0]) # 첫번째 차원을 전체 선택한 상황에서 첫번째 차원의 첫번째 것만 가져온다.\n",
    "print(t_2d[:, 0].size()) # ↑ 위의 경우의 크기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e202fc7-6f34-4b2b-8fd3-81e7b67baf24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 2.,  5.,  8., 11.])\n",
      "torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "print(t_2d[:, 1]) # 첫번째 차원을 전체 선택한 상황에서 두번째 차원의 첫번째 것만 가져온다.\n",
    "print(t_2d[:, 1].size()) # ↑ 위의 경우의 크기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b6de5175-4fa3-48ba-902f-0694c8370893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 3.,  6.,  9., 12.])\n",
      "torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "print(t_2d[:, -1]) # 첫번째 차원을 전체 선택한 상황에서 세번째 차원의 첫번째 것만 가져온다.\n",
    "print(t_2d[:, -1].size()) # ↑ 위의 경우의 크기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d914555-a8a0-40b1-8563-3787dc25cc13",
   "metadata": {},
   "source": [
    "# 브로드캐스팅\n",
    "## (주의 행렬 간 크기가 달라도 알아서 계산해주므로 오류도 안 난다)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9356d614-993d-484e-aa76-414d975cafdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5., 5.]])\n"
     ]
    }
   ],
   "source": [
    "m1 = torch.FloatTensor([[3, 3]])\n",
    "m2 = torch.FloatTensor([[2, 2]])\n",
    "print(m1 + m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a69f1f-61b6-446f-a9fd-1ca51ce22ebf",
   "metadata": {},
   "source": [
    "### 행렬 인덱싱, 슬라이싱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1d6844bd-ae1e-472c-8ab3-80c5795d824c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2])\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(m1.size())\n",
    "print(m1.dim())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f32029e8-2575-489a-aa3f-41e791eb6aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.])\n",
      "tensor([3.])\n",
      "tensor([2.])\n",
      "tensor([2.])\n"
     ]
    }
   ],
   "source": [
    "print(m1[:,0])\n",
    "print(m1[:,1])\n",
    "print(m2[:,0])\n",
    "print(m2[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b423215e-eced-42a8-b2ed-c04dd496d978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4., 5.]])\n"
     ]
    }
   ],
   "source": [
    "# Vector + scalar(원래 계산 불가)\n",
    "m1 = torch.FloatTensor([[1, 2]])\n",
    "m2 = torch.FloatTensor([3]) # [3] -> [3, 3](알아서 스칼라에서 벡터로 변경)\n",
    "print(m1 + m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0a5433-89ef-4c96-8daa-bfa992b6af2f",
   "metadata": {},
   "source": [
    "#### m1의 크기는 (1, 2) m2의 크기는 (2, 1)였습니다. 이 두 벡터는 원래 수학적으로는 덧셈을 수행할 수 없습니다.\n",
    "#### 그러나 파이토치는 두 벡터의 크기를 (2, 2)로 변경하여 덧셈을 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eabbf93d-60f5-4aaa-a310-46dc68618854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2])\n",
      "torch.Size([2, 1])\n",
      "tensor([[4., 5.],\n",
      "        [5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "# 2 x 1 Vector + 1 x 2 Vector\n",
    "m1 = torch.FloatTensor([[1, 2]])\n",
    "m2 = torch.FloatTensor([[3], [4]])\n",
    "print(m1.size()) # 1행 2열\n",
    "print(m2.size()) # 2행 1열\n",
    "print(m1 + m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cc554c-d35f-42d5-a6fe-d66ae77caa37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 브로드캐스팅 과정에서 실제로 두 텐서가 어떻게 변경되는지 보겠습니다.\n",
    "[1, 2]\n",
    "==> [[1, 2],\n",
    "     [1, 2]]\n",
    "[3]\n",
    "[4]\n",
    "==> [[3, 3],\n",
    "     [4, 4]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ba1814-ec3c-4a08-ab4e-4914187bcd81",
   "metadata": {},
   "source": [
    "### 행렬 곱셈과 곱셈의 차이(Matrix Multiplication Vs. Multiplication)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa7713d-6c34-4dfd-8647-a8951966442d",
   "metadata": {},
   "source": [
    "- 행렬로 곱셈을 하는 방법은 크게 두 가지가 있습니다. 바로 행렬 곱셈(.matmul)과 원소 별 곱셈(.mul)입니다.\n",
    "파이토치 텐서의 행렬 곱셈을 보겠습니다. 이는 matmul()을 통해 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9bc82e4-3bb6-4e7c-bc92-a953cd1cc345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Matrix 1:  torch.Size([2, 2])\n",
      "Shape of Matrix 2:  torch.Size([2, 1])\n",
      "matmul tensor([[ 5.],\n",
      "        [11.]])\n",
      "mul tensor([[1., 2.],\n",
      "        [6., 8.]])\n"
     ]
    }
   ],
   "source": [
    "m1 = torch.FloatTensor([[1, 2], [3, 4]])\n",
    "m2 = torch.FloatTensor([[1], [2]])\n",
    "print('Shape of Matrix 1: ', m1.shape) # 2 x 2\n",
    "print('Shape of Matrix 2: ', m2.shape) # 2 x 1\n",
    "#우리가 아는 행렬의 곱(내적)\n",
    "print('matmul',m1.matmul(m2)) # 2 x 1\n",
    "#브로드캐스팅으로 차원이 바뀐다\n",
    "print('mul',m1.mul(m2)) # 2 x 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e020f16d-d397-42e5-9e8d-c7407717e516",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
